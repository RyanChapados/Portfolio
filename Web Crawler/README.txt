hw3 for IS4200

This is a webcrawler designed to be given several seed links, collecting all outlinks from the seed links, 
ranking the oulinks based on several factors, then continuing to crawl based on the results of the ranking.
This assignment had me crawling 40,000 documents, so this crawler is designed for an amount of around that scale.
However, it does take a really long time (a few days) to crawl all these documents.
Later in the course I indexed all of the documents gathered using an elasticsearch index.